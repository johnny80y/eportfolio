<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Introduction (Unit 1)</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
					<h1 id="logo"><a href="Landing_Page_Module_3.html">back</a></h1>
					<nav id="nav">
						<ul>
							<li><a href="index.html">home</a></li>
							
							<li><a href="../contact.html">Get in Touch</a></li>
						</ul>
					</nav>
				</header>

			<!-- Main -->
				<div id="main" class="wrapper style1">
					<div class="container" align="justify">
						<header class="major">
							<h2>Introduction (Unit 1)</h2>
							<p>Deciphering Big Data</p>
						</header>

						<!-- Content -->
							<section id="content">
								<a href="#" class="image fit"><img src="images/ink_cropped.jpg" alt="" /></a> <!-- original image: pic07.jpg -->
								
<!-- Entry 1 -->
								<p>
									<h3>Expectations for this Module </h3>
									(25 January 2023)
								</p>
								<p>
									This short post will explain my background and my expectations for this module. I hope to compare the module’s progress with these expectations to get a better understanding of my academic progression. 
								</p>
								<p>
									I have a background in data analytics and statistics, so I am very familiar with data wrangling. I can use both R and Python for this purpose and have experience in generating data, cleaning it, merging it with other datasets, structuring it, and finally analyzing it. 
								</p>
								<p>
									From this module, I hope to learn how to apply my existing skills to Big Data. Thus far, I have only worked with smaller datasets containing a few thousand rows. However, Big Data requires different tools, libraries, and processing strategies. I hope to gain insights into concepts such as batch processing or event stream processing. I also expect to learn theoretical models for data processing pipelines. Finally, I hope to learn from my professor and fellow students about their experiences with Big Data and related topics.
								</p>
								<p>
									A challenge I expect to face lies in the graded project. My previous experiences with group projects have been very mixed, so I am anxious about that part of the module. Luckily, there are ways to reduce freeriding, for example by randomizing assignments, as Swaray (2012) demonstrated.
								</p>
								<b> Sources </b>
								<ul>
									<li> Swaray, R. (2012) An evaluation of a group project designed to reduce free-riding and promote active learning. <i>Assessment & Evaluation in Higher Education</i> 37(3), 285-292. DOI: http://dx.doi.org/10.1080/02602938.2010.531246</li>
								</ul>

								


<!-- Entry 2 --> <br>
								<p>
									<h3>First Peer Discussion – Initial Post</h3>
									(27 January 2023)
								</p>
								<p>
									Huxley (2020) discusses various ways of cleaning quantitative data and explains the statistical implications of various mathematical transformations. In the context of the Internet of Things (IoT), massive data streams lead to new challenges. Tejada (2023) describes how data from IoT devices is often processed in low-latency, high-volume environments. The Lambda and Kappa Architectures, for example, try to facilitate analysis by piping the data through a cold and hot path (batch layer vs. speed layer) simultaneously.
								</p>
								<p>
									While many data processing steps can be automated, machines will sometimes struggle with making appropriate decisions about cleaning and transformations. For example, Huxley (2020) explains how extreme values may result from collection errors, misrepresentations, faulty measuring equipment, or sampling errors. It often takes careful consideration and sometimes an active investigation to find the source of the error and know how to fix a particular data point. Unfortunately, manual or even semi-automated processes are impractical in the Big Data context (Gudivada et al. 2017).
								</p>
								<p>
									Luckily, Machine Learning can be used to distinguish between high- and low-quality data. For example, Wang et al (2020) proposed a “cleaning model” for wireless sensory 5G networks. The model was trained on reliable data and used to automate certain cleaning steps before allowing IoT sensory data to be uploaded to the cloud and used for further analysis.
								</p>
								<p>
									Also, I hypothesize that the sheer mass of data from IoT devices may partially mitigate cleaning issues. Faulty data is numerically insignificant against the enormous amount of other data points - at least as long as errors remain a rare exception. Whether the latter condition is met will, I expect, require careful manual analysis in most cases.
								</p>


								<b> Sources </b>
								<ul>
									<li> Gudivada, V., Apon, A. & Ding, J. (2017) Data Quality Considerations for Big Data and Machine Learning: Going Beyond Data Cleaning and Transformations. <i>International Journal on Advances in Software</i> 10(1): 1-20.
									</li>
									<li>
										Huxley, K. (2020) ‘Data Cleaning’, in Atkinson, P., Delamont, S., Cernat, A., Sakshaug, J. & Williams, R. (eds.) <i>SAGE Research Methods Foundations</i>. DOI: https://dx.doi.org/10.4135/9781526421036842861
									</li>
									<li>
										Tejada (2023) Big Data Architectures. Available from: https://learn.microsoft.com/en-us/azure/architecture/data-guide/big-data/ [Accessed 27 January 2023].
									</li>
									<li>
										Wang et al. (2020) Big Data Cleaning Based on Mobile Edge Computing in Industrial Sensor-Cloud. <i>IEEE Transactions on Industrial Informatics</i> 16(2): 1321-1329. DOI: https://doi.org/10.1109/TII.2019.2938861
									</li>
								</ul>
								
								

<!-- Entry 3 --><br>
								<p>
									<h3>Reflection on Unit 1’s Activities</h3>
									(29 January 2023)
								</p>
								<p>
									The first unit taught us that “data wrangling is the process that ensures that the data is in a format that is clean, accurate, formatted, and ready to be used for data analysis” (Sarkar & Roychowdhury 2019, 7). We went on to cover data transformations and data types. Given my background in data analytics, this was a revision of things I already knew quite well.
								</p>
								<p>
									A concept that stuck out to me was the three or four Vs of Big Data. The required reading by Sarkar and Roychowdhury (2019, 8) listed three Vs (Volume, Velocity, Variety), whereas the lecturecast (University of Essex 2023) listed four Vs (Volume, Velocity, Variety, and Veracity). I find the inclusion of Veracity of utmost importance as only valid and accurate data is useful for analytical purposes. The other three Vs essentially depend on Veracity.
								</p>
								<p>
									Comically, the lecturecast at one point misspelled “Veracity” as “Voracity”, which nonetheless accurately describes how many companies view data. Voraciously collecting data is a common strategy but not one that will inherently lead to improved models. I thought this was an amusing and also thought-provoking spelling error.
								</p>


								<b> Sources </b>
								<ul>
									<li> 
										Sarkar, T. & Roychowdhury, S. (2019) <i>Data Wrangling with Python</i>. 1st ed. Birmingham: Packt Publishing Ltd.
									</li>
									<li>
										University of Essex (2023) Big Data, Data Types, and Data Formats. Available from: https://www.my-course.co.uk/mod/scorm/player.php?a=10487&currentorg=articulate_rise&scoid=21028&sesskey=dC9u5XG16U&display=popup&mode=normal [Accessed 26 January 2023].
									</li>
								</ul>



							</section>

					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<ul class="icons">
						<li><a href="https://twitter.com/RealJohnGeiger" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://de.linkedin.com/in/johannes-geiger?trk=people-guest_people_search-card" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://www.instagram.com/realjohngeiger/" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
						<li><a href="https://github.com/johnny80y/" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</footer>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
