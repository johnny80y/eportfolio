<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Data Sources (Units 2-3)</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
					<h1 id="logo"><a href="Landing_Page_Module_3.html">back</a></h1>
					<nav id="nav">
						<ul>
							<li><a href="index.html">home</a></li>
							
							<li><a href="../contact.html">Get in Touch</a></li>
						</ul>
					</nav>
				</header>

			<!-- Main -->
				<div id="main" class="wrapper style1">
					<div class="container">
						<header class="major">
							<h2>Data Sources (Units 2-3)</h2>
							<p>Deciphering Big Data</p>
						</header>

						<!-- Content -->
							<section id="content">
								<a href="#" class="image fit"><img src="images/ink_cropped.jpg" alt="" /></a> <!-- original image: pic07.jpg -->
								<h3>File Handling - Unit 2 (04.02.2023)</h3>
								<p>
									<p>The reading for Unit 2 included instructions about opening, modifying, and closing files in Python (Sarkar & Roychowdhury 2019). As I work in the cybersecurity field, I know from personal experience that ransomware is one of the largest and most expensive threats that companies face today. In fact, according to some reports, there were over 230 million ransomware attacks in the first half of 2022 alone (Griffiths 2023). Notably, this number also includes unsuccessful attacks but that does not diminish the threat posed by this particular type of malware. </p>
									<p>In order to practice some of the python skills we learned during Unit 2, I decided to start coding my own (very basic and not truly functional) ransomware. It is hosted on GitHub and can be viewed here: <a href="https://github.com/johnny80y/Demo-Ransomware">Demo Ransomware Repository</a></p>
									<p>Note that this Python script was created to practice file handling only. The “ransomware” only encrypts .txt-files in a hard-coded demo directory, it drops the encryption key in that same directory, and it uses an insecure symmetric cipher. This ensures that my code is unusable for malicious purposes and it kept the project more manageable.</p>
									<p>What I learned was that Python is a powerful tool for handling files. Playing around with other file types such as .csv od .docx files also worked well, though the more complicated the format got, the more difficulty I was having parsing it (e.g. complicated .docx-files). Overall, I learned why Python is so popular for parsing Big Data consisting of unstructured files. It is simple to use and, as Thomas (2021) found, it is faster than many competing languages.</p>
																		
								</p>
								
								<b> Sources </b>
								<ul>
								<li> Griffiths, C. (2023) The Latest 2023 Ransomware Statistics (updated January 2023). Available From: https://aag-it.com/the-latest-ransomware-statistics/#:~:text=In just the first half,prevalence of this cyber threat. [Accessed 04.02.2023].</li>
								<li>Sarkar, T. & Roychowdhury, S. (2019) Data Wrangling with Python. 1st ed. Birmingham: Packt Publishing Ltd.</li>
								<li>Thomas, T. (2021) File Processing in Big Data Systems: Which is Quicker? Which is better? Available from: https://medium.com/geekculture/file-processing-a-comparative-analytics-study-e21b4693b70c [Accessed 04.02.2023].</li>
								</ul>
								
								<!-- Next Entry -->
								<br>
								<h3>Web Scraping - Unit 3 (08.02.2023)</h3>
								<p>
									<p>One of this week’s main topics was web scraping using the BeautifulSoup and Requests libraries in Python. Simply defined, web scraping is “a technique to extract data from the World Wide Web (WWW) and save it to a file system or database for later retrieval or analysis” (Zhao, 2017). This technique allows the (semi-)automated collection of information from one or several websites, that would otherwise require significant manual labor.</p>
									<p>The week’s formative activity required us to “Write a web scraping script in Python […] and parse this data into either an XML or JSON file. Perform the web scraping with the beautifulsoup4 and Request program modules.” (University of Essex 2023a). To tackle this activity, I referred to the required reading (Sarkar & Roychowdhury 2019) as well as a YouTube tutorial (Schafer 2017). The information I wanted to scrape was the list of postgraduate computing courses offered by the University of Essex. Note that the robots.txt-file does not forbid crawling of the URL I was interested in, so I was not breaking any university rules with this exercise (University of Essex 2023b). To achieve this, I wrote the following Python script:</p>
									<pre>
										from bs4 import BeautifulSoup
import requests
import pandas as pd

source = requests.get('https://online.essex.ac.uk/subjects/computing#PGcourselis').content # get the html code of the website
soup = BeautifulSoup(source, 'lxml')

courseList = soup.find_all('div', class_ = 'courses-grid-item-wrapper')
# returns a list of all these elements

titleResults = []
modeResults = []
locationResults = []
durationResults = []

for course in courseList:
    courseText = course.a.text # grab the text only
    courseText = courseText.replace('\t', '')   # remove tabs
    courseTextStringList = courseText.split('\n')   # save a list of strings with the different lines

    title = courseTextStringList[3] # get title
    mode = courseTextStringList[8] # get study mode
    location = courseTextStringList[12] # get location
    duration = courseTextStringList[16] # get duration
	
		titleResults.append(title)
    modeResults.append(mode)
    locationResults.append(location)
    durationResults.append(duration)

# Turn the resulting list to a pandas dataframe:
df = pd.DataFrame(list(zip(titleResults, modeResults, locationResults, durationResults)),
               columns =['Title', 'Study_Mode', 'Location', 'Duration'])

# Save as .json-file:
df.to_json('Essex_PG_Computing_Program.json', orient='records')
									</pre>

								</p>
								
								<b> Sources </b>
								<ul>
								<li> Gudivada, V., Apon, A. & Ding, J. (2017) Data Quality Considerations for Big Data and Machine Learning: Going Beyond Data Cleaning and Transformations. International Journal on Advances in Software 10(1): 1-20. </li>
								<li>Huxley, K. (2020) ‘Data Cleaning’, in Atkinson, P., Delamont, S., Cernat, A., Sakshaug, J. & Williams, R. (eds.) SAGE Research Methods Foundations. DOI: https://dx.doi.org/10.4135/9781526421036842861</li>
								<li>Tejada (2023) Big Data Architectures. Available from: https://learn.microsoft.com/en-us/azure/architecture/data-guide/big-data/ [Accessed 27 January 2023].</li>
								<li>Wang et al. (2020) Big Data Cleaning Based on Mobile Edge Computing in Industrial Sensor-Cloud. IEEE Transactions on Industrial Informatics 16(2): 1321-1329. DOI: https://doi.org/10.1109/TII.2019.2938861</li>
								</ul>
								
								<!-- Next Entry -->
								<br>
								<h3>Reflection on Unit 1’s Activities</h3>
								<p>
									<p>The first unit taught us that “data wrangling is the process that ensures that the data is in a format that is clean, accurate, formatted, and ready to be used for data analysis” (Sarkar & Roychowdhury 2019, 7). We went on to cover data transformations and data types. Given my background in data analytics, this was a revision of things I already knew quite well.</p>
									<p>A concept that stuck out to me was the three or four Vs of Big Data. The required reading by Sarkar and Roychowdhury (2019, 8) listed three Vs (Volume, Velocity, Variety), whereas the lecturecast (University of Essex 2023) listed four Vs (Volume, Velocity, Variety, and Veracity). I find the inclusion of Veracity of utmost importance as only valid and accurate data is useful for analytical purposes. The other three Vs essentially depend on Veracity.</p>
									<p>Comically, the lecturecast at one point misspelled “Veracity” as “Voracity”, which nonetheless accurately describes how many companies view data. Voraciously collecting data is a common strategy but not one that will inherently lead to improved models. I thought this was an amusing and also thought-provoking spelling mistake.</p>
								</p>
								<b>Sources</b>
								<ul>
									<li>Sarkar, T. & Roychowdhury, S. (2019) Data Wrangling with Python. 1st ed. Birmingham: Packt Publishing Ltd.</li>
									<li>University of Essex (2023) Big Data, Data Types, and Data Formats. Available from: https://www.my-course.co.uk/mod/scorm/player.php?a=10487&currentorg=articulate_rise&scoid=21028&sesskey=dC9u5XG16U&display=popup&mode=normal [Accessed 26 January 2023].</li>
								</ul>




							</section>

					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<ul class="icons">
						<li><a href="https://twitter.com/RealJohnGeiger" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://de.linkedin.com/in/johannes-geiger?trk=people-guest_people_search-card" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://www.instagram.com/realjohngeiger/" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
						<li><a href="https://github.com/johnny80y/" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</footer>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
